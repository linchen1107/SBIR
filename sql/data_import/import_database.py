#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
NSNæ–™è™Ÿç”³ç·¨ç³»çµ± - è³‡æ–™åº«åŒ¯å…¥å·¥å…·
(é©ç”¨æ–¼ Docker ç’°å¢ƒ)
"""

import os
import sys
import time
import psycopg2
import logging
from datetime import datetime
from pathlib import Path

# --- æ–°çš„ã€æ›´å¯é çš„è·¯å¾‘è¨­å®š ---
script_dir = Path(__file__).parent.resolve()
project_root = script_dir.parent.parent
sys.path.insert(0, str(project_root))
# --- çµæŸè·¯å¾‘è¨­å®š ---

from sql.database_config.database_config import get_db_config_instance

class DatabaseImporter:
    """è³‡æ–™åº«åŒ¯å…¥å™¨"""

    def __init__(self):
        # --- FINAL FIX: Hardcode connection params to bypass all environment issues ---
        self.db_config = {
            "host": "postgres",
            "port": 5432,
            "dbname": "nsn_database",
            "user": "postgres",
            "password": "postgres",
        }
        # --- END FIX ---
        self.script_dir = Path(__file__).parent.resolve()
        self.setup_logging()
        
        # SQLæª”æ¡ˆæ¸…å–®ï¼ˆæŒ‰ç…§é †åºï¼‰
        self.sql_files = [
            "00_import_fsg.sql", "01_import_mrc_key_group.sql", 
            "02_import_reply_table.sql", "03_import_fsc.sql",
            "04_import_nato_h6_item_name.sql", "05_import_inc.sql",
            "06_import_mrc.sql", "07_import_mode_code_edit.sql",
            "08_import_inc_fsc_xref.sql", "09_import_nato_h6_inc_xref.sql",
            "10_import_colloquial_inc_xref.sql", "11_import_fiig.sql",
            "12_import_mrc_reply_table_xref.sql", "13_import_fiig_inc_xref.sql",
            "14_import_fiig_inc_mrc_xref.sql"
        ]

    def setup_logging(self):
        """è¨­å®šæ—¥èªŒè¨˜éŒ„"""
        log_filename = self.script_dir / f"import_log_{datetime.now().strftime('%Y%m%d_%H%M%S')}.log"
        
        logging.basicConfig(
            level=logging.INFO,
            format='%(asctime)s - %(levelname)s - %(message)s',
            handlers=[
                logging.FileHandler(log_filename, encoding='utf-8'),
                logging.StreamHandler(sys.stdout)
            ]
        )
        self.logger = logging.getLogger(__name__)
        self.logger.info(f"æ—¥èªŒæª”æ¡ˆ: {log_filename}")

    def test_connection(self):
        """æ¸¬è©¦è³‡æ–™åº«é€£ç·š"""
        try:
            conn = psycopg2.connect(**self.db_config)
            cursor = conn.cursor()
            cursor.execute("SELECT version();")
            version = cursor.fetchone()[0]
            cursor.close()
            conn.close()
            self.logger.info("âœ… è³‡æ–™åº«é€£ç·šæˆåŠŸ")
            self.logger.info(f"PostgreSQLç‰ˆæœ¬: {version}")
            return True
        except Exception as e:
            self.logger.error(f"âŒ è³‡æ–™åº«é€£ç·šå¤±æ•—: {e}")
            return False

    def execute_sql_file(self, filename):
        """åŸ·è¡Œå–®ä¸€SQLæª”æ¡ˆ"""
        filepath = self.script_dir / filename
        if not filepath.exists():
            self.logger.error(f"âŒ æª”æ¡ˆä¸å­˜åœ¨: {filepath}")
            return False
        
        file_size_mb = filepath.stat().st_size / (1024 * 1024)
        self.logger.info(f"ğŸ“„ æº–å‚™åŸ·è¡Œ: {filename} ({file_size_mb:.1f} MB)")
        
        if file_size_mb > 50: # å¤§æª”æ¡ˆè­¦å‘Š
             self.logger.info(f"âš ï¸  å¤§æª”æ¡ˆè­¦å‘Š: æ­¤æª”æ¡ˆè¼ƒå¤§ ({file_size_mb:.1f} MB)ï¼Œé è¨ˆéœ€è¦è¼ƒé•·æ™‚é–“...")

        try:
            with open(filepath, 'r', encoding='utf-8') as f:
                sql_content = f.read()
            
            conn = psycopg2.connect(**self.db_config)
            conn.autocommit = True
            cursor = conn.cursor()
            
            start_time = time.time()
            cursor.execute(sql_content)
            end_time = time.time()
            
            self.logger.info(f"âœ… å®Œæˆ: {filename}, è€—æ™‚: {end_time - start_time:.2f}ç§’")
            
            cursor.close()
            conn.close()
            return True
        except Exception as e:
            self.logger.error(f"âŒ åŸ·è¡Œå¤±æ•—: {filename}")
            self.logger.error(f"éŒ¯èª¤è©³æƒ…: {e}")
            return False

    def run_import(self):
        """åŸ·è¡Œå®Œæ•´çš„åŒ¯å…¥æµç¨‹"""
        db_info = self.db_config
        self.logger.info("=" * 60)
        self.logger.info("  NSNæ–™è™Ÿç”³ç·¨ç³»çµ± - è³‡æ–™åº«åŒ¯å…¥å·¥å…· (Dockerç‰ˆ)")
        self.logger.info(f"  ç›®æ¨™è³‡æ–™åº«: {db_info.get('host')}:{db_info.get('port')}/{db_info.get('dbname')}")
        self.logger.info("=" * 60)
        
        if not self.test_connection():
            return False
        
        start_time = time.time()
        success_count = 0
        
        for i, filename in enumerate(self.sql_files, 1):
            self.logger.info(f"ğŸš€ [{i:2d}/{len(self.sql_files)}] åŸ·è¡Œä¸­...")
            if self.execute_sql_file(filename):
                success_count += 1
                self.logger.info(f"âœ… [{i:2d}/{len(self.sql_files)}] å®Œæˆ\n")
            else:
                self.logger.error(f"âŒ [{i:2d}/{len(self.sql_files)}] å¤±æ•—ï¼Œåœæ­¢åŸ·è¡Œ")
                return False
        
        total_time = time.time() - start_time
        self.logger.info("=" * 60)
        self.logger.info("ğŸ‰ è³‡æ–™åŒ¯å…¥å®Œæˆï¼")
        self.logger.info(f"âœ… æˆåŠŸåŸ·è¡Œ: {success_count}/{len(self.sql_files)} å€‹æª”æ¡ˆ")
        self.logger.info(f"â±ï¸  ç¸½è€—æ™‚: {total_time//60:.0f}åˆ†{total_time%60:.1f}ç§’")
        return True

def main():
    """ä¸»å‡½æ•¸"""
    importer = DatabaseImporter()
    if not importer.run_import():
        sys.exit(1)

if __name__ == "__main__":
    main()
