#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
å®¢è£½åŒ– NSN è³‡æ–™åŒ¯å…¥å·¥å…·
è³‡æ–™åº«: sbir_equipment_db_v3
ç›®æ¨™ Schema: public
"""

import os
import sys
import time
import psycopg2
import logging
from datetime import datetime
from pathlib import Path

class NSNDataImporter:
    """NSN è³‡æ–™åŒ¯å…¥å™¨ï¼ˆå®¢è£½åŒ–ç‰ˆæœ¬ï¼‰"""

    def __init__(self, db_host='localhost', db_port=5432, db_name='sbir_equipment_db_v3', 
                 db_user='postgres', db_password='willlin07'):
        """
        åˆå§‹åŒ–åŒ¯å…¥å™¨
        
        Args:
            db_host: è³‡æ–™åº«ä¸»æ©Ÿ
            db_port: è³‡æ–™åº«åŸ è™Ÿ
            db_name: è³‡æ–™åº«åç¨±
            db_user: ä½¿ç”¨è€…åç¨±
            db_password: å¯†ç¢¼
        """
        self.db_config = {
            "host": db_host,
            "port": db_port,
            "dbname": db_name,
            "user": db_user,
            "password": db_password,
            "options": "-c search_path=public"  # å›ºå®šä½¿ç”¨ public schema
        }
        
        # è¨­å®šè³‡æ–™ä¾†æºç›®éŒ„ï¼ˆçµ•å°è·¯å¾‘ï¼‰
        self.script_dir = Path(__file__).parent.resolve()
        # å¾ Database/scripts/03-data-import å¾€ä¸Šåˆ°å°ˆæ¡ˆæ ¹ç›®éŒ„ï¼Œå†åˆ° sql/data_import
        project_root = self.script_dir.parent.parent.parent
        self.data_source_dir = project_root / 'sql' / 'data_import'
        
        self.setup_logging()
        
        # SQLæª”æ¡ˆæ¸…å–®ï¼ˆæŒ‰ç…§ä¾è³´é †åºï¼‰
        self.sql_files = [
            # åŸºç¤è³‡æ–™è¡¨ï¼ˆç„¡ä¾è³´ï¼‰
            "00_import_fsg.sql",              # FSG è¯é‚¦è£œçµ¦ç¾¤çµ„
            "01_import_mrc_key_group.sql",    # MRC ç¾¤çµ„
            "02_import_reply_table.sql",      # å›æ‡‰è¡¨ä¸»æª”
            
            # åˆ†é¡è¡¨ï¼ˆä¾è³´ FSGï¼‰
            "03_import_fsc.sql",              # FSC è¯é‚¦è£œçµ¦åˆ†é¡
            
            # NATO å’Œ INC è¡¨
            "04_import_nato_h6_item_name.sql", # NATO H6 ç‰©å“åç¨±
            "05_import_inc.sql",              # INC ç‰©å“åç¨±ä»£ç¢¼
            
            # MRC å’Œæ¨¡å¼ç¢¼
            "06_import_mrc.sql",              # MRC ç‰©æ–™éœ€æ±‚ä»£ç¢¼
            "07_import_mode_code_edit.sql",   # æ¨¡å¼ç¢¼ç·¨è¼¯æŒ‡å—
            
            # é—œè¯è¡¨ï¼ˆä¾è³´å¤šå€‹ä¸»è¡¨ï¼‰
            "08_import_inc_fsc_xref.sql",     # INC-FSC å°æ‡‰
            "09_import_nato_h6_inc_xref.sql", # H6-INC å°æ‡‰
            "10_import_colloquial_inc_xref.sql", # ä¿—èª INC å°æ‡‰
            
            # FIIG ç³»çµ±
            "11_import_fiig.sql",             # FIIG è­˜åˆ¥æŒ‡å—
            
            # è¤‡é›œé—œè¯ï¼ˆä¾è³´ MRC å’Œ FIIGï¼‰
            "12_import_mrc_reply_table_xref.sql",  # MRC-å›æ‡‰è¡¨å°æ‡‰
            "13_import_fiig_inc_xref.sql",    # FIIG-INC å°æ‡‰
            "14_import_fiig_inc_mrc_xref.sql" # FIIG-INC-MRC ä¸‰å…ƒå°æ‡‰ï¼ˆæœ€å¤§æª”æ¡ˆï¼‰
        ]

    def setup_logging(self):
        """è¨­å®šæ—¥èªŒè¨˜éŒ„"""
        log_dir = self.script_dir
        log_filename = log_dir / f"nsn_import_log_{datetime.now().strftime('%Y%m%d_%H%M%S')}.log"
        
        logging.basicConfig(
            level=logging.INFO,
            format='%(asctime)s - %(levelname)s - %(message)s',
            handlers=[
                logging.FileHandler(log_filename, encoding='utf-8'),
                logging.StreamHandler(sys.stdout)
            ]
        )
        self.logger = logging.getLogger(__name__)
        self.logger.info(f"æ—¥èªŒæª”æ¡ˆ: {log_filename}")

    def test_connection(self):
        """æ¸¬è©¦è³‡æ–™åº«é€£ç·š"""
        try:
            conn = psycopg2.connect(**self.db_config)
            cursor = conn.cursor()
            
            # æª¢æŸ¥ PostgreSQL ç‰ˆæœ¬
            cursor.execute("SELECT version();")
            version = cursor.fetchone()[0]
            
            # æª¢æŸ¥ public schema æ˜¯å¦å­˜åœ¨
            cursor.execute("""
                SELECT schema_name 
                FROM information_schema.schemata 
                WHERE schema_name = 'public';
            """)
            if not cursor.fetchone():
                self.logger.error("âŒ public schema ä¸å­˜åœ¨ï¼")
                return False
            
            # æª¢æŸ¥ public schema ä¸­çš„è¡¨æ ¼æ•¸é‡
            cursor.execute("""
                SELECT COUNT(*) 
                FROM pg_tables 
                WHERE schemaname = 'public';
            """)
            table_count = cursor.fetchone()[0]
            
            cursor.close()
            conn.close()
            
            self.logger.info("âœ… è³‡æ–™åº«é€£ç·šæˆåŠŸ")
            self.logger.info(f"   PostgreSQL: {version.split(',')[0]}")
            self.logger.info(f"   public schema: {table_count} å€‹è¡¨æ ¼")
            return True
            
        except Exception as e:
            self.logger.error(f"âŒ è³‡æ–™åº«é€£ç·šå¤±æ•—: {e}")
            return False

    def execute_sql_file(self, filename):
        """åŸ·è¡Œå–®ä¸€ SQL æª”æ¡ˆ"""
        filepath = self.data_source_dir / filename
        
        if not filepath.exists():
            self.logger.error(f"âŒ æª”æ¡ˆä¸å­˜åœ¨: {filepath}")
            return False
        
        file_size_mb = filepath.stat().st_size / (1024 * 1024)
        self.logger.info(f"ğŸ“„ æº–å‚™åŸ·è¡Œ: {filename} ({file_size_mb:.1f} MB)")
        
        # å¤§æª”æ¡ˆè­¦å‘Š
        if file_size_mb > 50:
            self.logger.info(f"âš ï¸  å¤§æª”æ¡ˆè­¦å‘Š: æ­¤æª”æ¡ˆè¼ƒå¤§ï¼Œé è¨ˆéœ€è¦è¼ƒé•·æ™‚é–“...")
        
        try:
            # è®€å– SQL å…§å®¹
            with open(filepath, 'r', encoding='utf-8') as f:
                sql_content = f.read()
            
            # é€£æ¥è³‡æ–™åº«ä¸¦åŸ·è¡Œ
            conn = psycopg2.connect(**self.db_config)
            conn.autocommit = True
            cursor = conn.cursor()
            
            start_time = time.time()
            cursor.execute(sql_content)
            end_time = time.time()
            
            elapsed = end_time - start_time
            self.logger.info(f"âœ… å®Œæˆ: {filename}, è€—æ™‚: {elapsed:.2f}ç§’")
            
            cursor.close()
            conn.close()
            return True
            
        except psycopg2.Error as e:
            self.logger.error(f"âŒ SQL åŸ·è¡Œå¤±æ•—: {filename}")
            self.logger.error(f"   éŒ¯èª¤: {e}")
            return False
        except Exception as e:
            self.logger.error(f"âŒ åŸ·è¡Œå¤±æ•—: {filename}")
            self.logger.error(f"   éŒ¯èª¤: {e}")
            return False

    def verify_import(self):
        """é©—è­‰åŒ¯å…¥çµæœ"""
        try:
            conn = psycopg2.connect(**self.db_config)
            cursor = conn.cursor()
            
            self.logger.info("\n" + "=" * 60)
            self.logger.info("è³‡æ–™åŒ¯å…¥é©—è­‰")
            self.logger.info("=" * 60)
            
            # æª¢æŸ¥ä¸»è¦è¡¨æ ¼çš„è³‡æ–™ç­†æ•¸
            tables_to_check = [
                ('fsg', 'FSG è¯é‚¦è£œçµ¦ç¾¤çµ„'),
                ('fsc', 'FSC è¯é‚¦è£œçµ¦åˆ†é¡'),
                ('nato_h6_item_name', 'NATO H6 ç‰©å“åç¨±'),
                ('inc', 'INC ç‰©å“åç¨±ä»£ç¢¼'),
                ('fiig', 'FIIG è­˜åˆ¥æŒ‡å—'),
                ('mrc', 'MRC ç‰©æ–™éœ€æ±‚ä»£ç¢¼'),
                ('reply_table', 'å›æ‡‰è¡¨'),
                ('fiig_inc_mrc_xref', 'FIIG-INC-MRC å°æ‡‰')
            ]
            
            for table_name, description in tables_to_check:
                cursor.execute(f"SELECT COUNT(*) FROM public.{table_name};")
                count = cursor.fetchone()[0]
                self.logger.info(f"  {description:30s}: {count:>8,} ç­†")
            
            cursor.close()
            conn.close()
            
            self.logger.info("=" * 60)
            return True
            
        except Exception as e:
            self.logger.error(f"âŒ é©—è­‰å¤±æ•—: {e}")
            return False

    def run_import(self, start_from=0, skip_confirmation=False):
        """
        åŸ·è¡Œå®Œæ•´çš„åŒ¯å…¥æµç¨‹
        
        Args:
            start_from: å¾ç¬¬å¹¾å€‹æª”æ¡ˆé–‹å§‹ï¼ˆ0-based indexï¼‰
            skip_confirmation: æ˜¯å¦è·³éç¢ºèªæç¤º
        """
        self.logger.info("=" * 60)
        self.logger.info("  NSN è³‡æ–™åŒ¯å…¥å·¥å…·ï¼ˆå®¢è£½åŒ–ç‰ˆæœ¬ï¼‰")
        self.logger.info(f"  ç›®æ¨™è³‡æ–™åº«: {self.db_config['host']}:{self.db_config['port']}/{self.db_config['dbname']}")
        self.logger.info(f"  ç›®æ¨™ Schema: public")
        self.logger.info("=" * 60)
        
        # æ¸¬è©¦é€£ç·š
        if not self.test_connection():
            self.logger.error("âŒ é€£ç·šæ¸¬è©¦å¤±æ•—ï¼Œçµ‚æ­¢åŸ·è¡Œ")
            return False
        
        # ç¢ºèªæç¤º
        if not skip_confirmation:
            self.logger.info("\nâš ï¸  æ³¨æ„: æ­¤æ“ä½œå°‡æ¸…é™¤ä¸¦é‡æ–°åŒ¯å…¥ public schema çš„æ‰€æœ‰ NSN è³‡æ–™")
            response = input("\næ˜¯å¦ç¹¼çºŒï¼Ÿ(yes/no): ").strip().lower()
            if response != 'yes':
                self.logger.info("âŒ ä½¿ç”¨è€…å–æ¶ˆæ“ä½œ")
                return False
        
        # é–‹å§‹åŒ¯å…¥
        start_time = time.time()
        success_count = 0
        total_files = len(self.sql_files) - start_from
        
        self.logger.info(f"\nğŸš€ é–‹å§‹åŒ¯å…¥ {total_files} å€‹æª”æ¡ˆ...\n")
        
        for i, filename in enumerate(self.sql_files[start_from:], start_from + 1):
            self.logger.info(f"[{i:2d}/{len(self.sql_files)}] åŸ·è¡Œä¸­...")
            
            if self.execute_sql_file(filename):
                success_count += 1
                self.logger.info(f"[{i:2d}/{len(self.sql_files)}] âœ… å®Œæˆ\n")
            else:
                self.logger.error(f"[{i:2d}/{len(self.sql_files)}] âŒ å¤±æ•—")
                self.logger.error(f"\nâš ï¸  åŒ¯å…¥åœ¨ç¬¬ {i} å€‹æª”æ¡ˆæ™‚å¤±æ•—ï¼Œæ˜¯å¦ç¹¼çºŒï¼Ÿ")
                response = input("ç¹¼çºŒåŸ·è¡Œå‰©é¤˜æª”æ¡ˆï¼Ÿ(yes/no): ").strip().lower()
                if response != 'yes':
                    self.logger.error("ä½¿ç”¨è€…é¸æ“‡åœæ­¢åŸ·è¡Œ")
                    break
        
        total_time = time.time() - start_time
        
        # é©—è­‰çµæœ
        self.verify_import()
        
        # è¼¸å‡ºæ‘˜è¦
        self.logger.info("\n" + "=" * 60)
        self.logger.info("ğŸ‰ è³‡æ–™åŒ¯å…¥æµç¨‹å®Œæˆï¼")
        self.logger.info(f"âœ… æˆåŠŸåŸ·è¡Œ: {success_count}/{total_files} å€‹æª”æ¡ˆ")
        self.logger.info(f"â±ï¸  ç¸½è€—æ™‚: {total_time//60:.0f}åˆ†{total_time%60:.1f}ç§’")
        self.logger.info("=" * 60)
        
        return success_count == total_files


def main():
    """ä¸»å‡½æ•¸"""
    import argparse
    
    parser = argparse.ArgumentParser(description='NSN è³‡æ–™åŒ¯å…¥å·¥å…·')
    parser.add_argument('--host', default='localhost', help='è³‡æ–™åº«ä¸»æ©Ÿ')
    parser.add_argument('--port', default=5432, type=int, help='è³‡æ–™åº«åŸ è™Ÿ')
    parser.add_argument('--database', default='sbir_equipment_db_v3', help='è³‡æ–™åº«åç¨±')
    parser.add_argument('--user', default='postgres', help='ä½¿ç”¨è€…åç¨±')
    parser.add_argument('--password', default='willlin07', help='å¯†ç¢¼')
    parser.add_argument('--start-from', default=0, type=int, help='å¾ç¬¬å¹¾å€‹æª”æ¡ˆé–‹å§‹ï¼ˆ0-basedï¼‰')
    parser.add_argument('--yes', action='store_true', help='è·³éç¢ºèªæç¤º')
    
    args = parser.parse_args()
    
    importer = NSNDataImporter(
        db_host=args.host,
        db_port=args.port,
        db_name=args.database,
        db_user=args.user,
        db_password=args.password
    )
    
    success = importer.run_import(
        start_from=args.start_from,
        skip_confirmation=args.yes
    )
    
    sys.exit(0 if success else 1)


if __name__ == "__main__":
    main()
